{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4423c47f-d67e-45d2-a7d6-9955c62f073b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistical Typing: A Runtime Typing System for Data Science and Machine Learning\n",
    "\n",
    "### Niels Bantilan\n",
    "\n",
    "Pycon, May 15th 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc1583",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Hey everyone, I'm Niels Bantilan, and I'm excited to present\n",
    "to you at Pycon this year. Just to give you a little background about myself, I'm one\n",
    "of the core maintainers of Flyte, which is an open source ML orchestration\n",
    "tool that helps ML/DS practitioners scale their workflows. I'm also the\n",
    "author of a dataframe validation tool called `pandera`, which is something\n",
    "I'll return to a little later. I want to start my presentation by making the\n",
    "claim that..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf856726-3f75-4f1f-abaf-4eefcb1aade3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Type systems help programmers reason about and write more robust code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85a529",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Type systems help programmers reason about and write more robust code. Since\n",
    "Python takes a gradual typing approach, you can opt in to using type hints\n",
    "and I've found that they improve readability and help me build a better\n",
    "mental model of what my code is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f36079",
   "metadata": {
    "lines_to_next_cell": 1,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "Number = Union[int, float]\n",
    "\n",
    "def add_and_double(x: Number, y: Number) -> Number:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ffee6b",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To see the benefits of type hints, if you take a look at this code snippet,\n",
    "you can see that we're defining a function called `add_and_double` which takes\n",
    "two numbers, either an `int` or a `float`, and produces another number,\n",
    "which is presumably the sum of the two numbers multiplied by two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82957b37",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "Can you predict the outcome of these function calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72833519",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_and_double(5, 2)\n",
    "add_and_double(5, \"hello\")\n",
    "add_and_double(11.5, -1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab90b742",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now I want you to take a few seconds to ask yourself: just with type\n",
    "hints and no actual implementation in the function body, can you predict the\n",
    "outcome of these function calls?\n",
    "\n",
    "We'll review this again later, but now I think we have enough context to\n",
    "get to the central question of my presentation, which is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4cdc75-c15c-4bf4-a170-643017d9e05d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ü§î What would a type system geared towards data science and machine learning look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f380f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbeb009",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "And to address this question, I'm going to..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487d549-81a5-405e-81ab-16ea4d6a016b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- üêûüêûüêû introduce you to some of my problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00caedd-9064-47fe-8278-1e79ffc24de2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- üìäüìà define a specification for data types in the statistical domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d6a6dc-f047-423e-af06-14ced07fc259",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- üõ† demonstrate one way it might be put into practice using `pandera`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeadf21",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- üèé discuss where this idea can go next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff79287-041c-4d55-bdb5-1bc7ef7a6b3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üêûüêûüêû An Introduction to Some of my Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46fddf6",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So first let me introduce you to some of my problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a887744",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The worst bugs are the silent ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef1e11-94e8-402c-8173-8eb74a564387",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The first one is that the worst bugs are the silent ones, especially if\n",
    "they're in ML models that took a lot of time to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70861490",
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Especially if they're in ML models that took a lot of ‚è∞ to train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35004053",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The Model is the Data, the Data is the Model ü§î ü§Ø"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ba73c",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To see why, consider the notion that statistical models are some kind of compression,\n",
    "representation, or approximation of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321da29",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "- `model ~ data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6587d324",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `Œîdata -> Œîmodel`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c5bc3d",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This implies that if the data changes, the model changes as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83293e5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- I define my `model` as a function `f(x) -> y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604fd1dc",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So really, when I'm using a model for explanatory or predictive purposes,\n",
    "at a high level we're really using the model as a function that takes some\n",
    "input x and produces a result y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da278a15",
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How do I know if `f` is working as intended?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10b728",
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The question is, how do I know if `f` is working as intended?\n",
    "\n",
    "Now there're many answers to this question, but here I'd like to highlight\n",
    "two approaches that are well established in the software development world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ade61",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Static Type-checking/Linting\n",
    "\n",
    "Catches certain type errors before running code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f5bbc",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The first approach is to catch certain type errors statically, even before\n",
    "running any code. So let's return to this example I should you in the beginning.\n",
    "Since Python 3.6 we've had type hints and tools like `mypy` can identify\n",
    "errors like the middle example which invokes `add_and_double` with an invalid\n",
    "type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d7291",
   "metadata": {
    "lines_to_next_cell": 1,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "Number = Union[int, float]\n",
    "\n",
    "def add_and_double(x: Number, y: Number) -> Number:\n",
    "    return (x + y) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71a91c",
   "metadata": {},
   "source": [
    "```python\n",
    "add_and_double(5, 2)        # ‚úÖ\n",
    "add_and_double(5, \"hello\")  # ‚ùå\n",
    "add_and_double(11.5, -1.5)  # ‚úÖ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a042d46",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Static Type-checking/Linting\n",
    "\n",
    "**Problem:** What if the underlying implementation is wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c44b2",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "But what if the underlying implementation is wrong? Type hints can only\n",
    "get us so far because the first and third call to `add_and_double` are\n",
    "valid invocations but the actual output is incorrect because the function\n",
    "body implements the wrong logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e60b7",
   "metadata": {
    "lines_to_next_cell": 1,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "Number = Union[int, float]\n",
    "\n",
    "def add_and_double(x: Number, y: Number) -> Number:\n",
    "    return (x - y) * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a8fbfc",
   "metadata": {},
   "source": [
    "```python\n",
    "add_and_double(5, 2)        # output: 12\n",
    "add_and_double(5, \"hello\")  # raises: TypeError\n",
    "add_and_double(11.5, -1.5)  # output: 52\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08c5f01",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Unit Tests\n",
    "\n",
    "Unit tests verify the behavior of isolated pieces of functionality and\n",
    "let you know when changes cause breakages or regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba773b",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is where unit tests come in. Unit tests verify the behavior of isolated\n",
    "pieces of functionality and let you know when changes cause breakages or regressions.\n",
    "As you can see, I've divided up my tests in terms of happy and sad path\n",
    "tests.\n",
    "\n",
    "In the happy path tests, I've manually written examples of valid inputs and\n",
    "test that the output is correct, whereas in the sad path tests, I've defined\n",
    "cases that should raise some sort of exception. Note that these tests\n",
    "right here are actualy redundant since the type linter should be able to\n",
    "catch TypeErrors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2a64cd",
   "metadata": {
    "lines_to_next_cell": 1,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "def test_add_and_double():\n",
    "    # üôÇ path\n",
    "    assert add_and_double(5, 2) == 14\n",
    "    assert add_and_double(11.5, -15) == 20.0\n",
    "    assert add_and_double(-10, 1.0) == -18.0\n",
    "\n",
    "def test_add_and_double_exceptions():\n",
    "    # üòû path\n",
    "    with pytest.raises(TypeError):\n",
    "        add_and_double(5, \"hello\")\n",
    "    with pytest.raises(TypeError):\n",
    "        add_and_double(\"world\", 32.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e94a9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Property-based Tests\n",
    "\n",
    "Property-based testing alleviates the burden of explicitly writing test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd282862",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "You might have noticed that it's burdensome to explicitly\n",
    "write test cases, so another thing we can do to be confident that a piece\n",
    "of functionality works as intended is to define property-based tests.\n",
    "\n",
    "Here I'm using the hypothesis library to define the interface of my function\n",
    "as typed strategies. When I run my test suite, under the hood hypothesis\n",
    "generates a bunch of data according to those types and attempts to falsify\n",
    "the assumption make in the test function body. If it does so, it then tries\n",
    "to find the smallest human-readable example that falsifies the test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29ced7",
   "metadata": {
    "lines_to_next_cell": 1,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from hypothesis import given\n",
    "from hypothesis.strategies import integers, floats, one_of, text\n",
    "\n",
    "numbers = one_of(integers(), floats())\n",
    "\n",
    "@given(x=numbers, y=numbers)\n",
    "def test_add_and_double(x, y):\n",
    "    assert add_and_double(x, y) == (x + y) * 2\n",
    "\n",
    "@given(x=numbers, y=text())\n",
    "def test_add_and_double_exceptions():\n",
    "    with pytest.raises(TypeError):\n",
    "        add_and_double(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4bf05-2ced-4571-9809-7ddd3f6740f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üîé ‚õè Testing code is hard, testing statistical analysis code is harder!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8e4ad",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This brings me to my next problem, which is that testing code is hard, but\n",
    "testing statistical analysis code is harder!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa26ab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Toy Example: Survey Data for Modeling"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63c077c1",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"mermaid\">\n",
    "    graph LR\n",
    "      U[User] --creates--> S([Survey Response])\n",
    "      S --store data--> D[(Database)]\n",
    "      D --create dataset--> X[(Dataset)]\n",
    "      X --train model--> M([Model])\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e941d9d6",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To see why, let's look at a toy example where we have a system that ingests\n",
    "survey data, stores responses in a database, creates a dataset, and trains\n",
    "a model to predict a target of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40431c8b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Toy Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5049423",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple, TypedDict\n",
    "\n",
    "Response = TypedDict(\"Response\", q1=int, q2=int, q3=str)\n",
    "Example = Tuple[List[float], bool]\n",
    "\n",
    "def store_data(raw_response: str) -> Response:\n",
    "    ...\n",
    "\n",
    "def create_dataset(raw_responses: List[Response], target: List[bool]) -> List[Example]:\n",
    "    ...\n",
    "\n",
    "def train_model(survey_responses: List[Example]) -> str:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8fd6f",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now here's what your pipeline might look like. To help with readability,\n",
    "I've defined two types:\n",
    "- one to represent the processed response\n",
    "- and another to represent a training example, which consists of a list of floats\n",
    "  for the features and a boolean value for the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9570c83",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "- `store_data`'s scope of concern is atomic, i.e. it only operates\n",
    "  on a single data point üßò‚öõ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab780ce",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "If we just focus on the `store_data` and `create_dataset` functions, you\n",
    "may notice that `store_data`'s scope of concern is atomic, in that it\n",
    "only operates on a single data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac12a2d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `create_dataset` needs to worry about the statistical patterns of a\n",
    "  sample of data points üòìüìä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71285ebf",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "On the other hand, `create_dataset` needs to worry\n",
    "about the overall statistical distribution of a data sample when it creates\n",
    "a dataset for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d202ef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So what if I want to test `create_dataset` on plausible example data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce604730",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Going back to the idea of unit testing to be confident that our model\n",
    "works as intended, I'd ideally want to test it with some data that looks\n",
    "reasonably close to what I'd see in the real world. So what if I want\n",
    "to test `create_dataset` on a plausible example data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c515ad3-e709-43a7-a9ae-a6333e82dad7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ü§≤ üìÄ üñº hand-crafting example dataframes is a major barrier for unit testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e168c7",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Unfortunately the main answer here is you'd need to hand-craft example data,\n",
    "which often takes the form of pandas dataframes, and the most I'll say on\n",
    "this topic is that it's not fun..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b16e682",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    ".... it's not fun üò≠"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d944c641",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What if I could do something like..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429789d7",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "What I'd like to be able to do is to specify the data types of my variables\n",
    "as a schema along with additional constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217240f",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f9a02",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import pandera as pa\n",
    "from pandera.typing import Series\n",
    "\n",
    "class SurveySchema(pa.SchemaModel):\n",
    "    q1: Series[int] = pa.Field(isin=[1, 2, 3, 4, 5])\n",
    "    q2: Series[int] = pa.Field(isin=[1, 2, 3, 4, 5])\n",
    "    q3: Series[str] = pa.Field(str_matches=\"[a-zA-Z0-9 ]+\")\n",
    "\n",
    "data = pd.DataFrame({\"q1\": [-1], \"q2\": [5], \"q3\": [\"hello\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc83d3",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Here you can see that I'm importing pandera and I'm using it to I've defined a schema for\n",
    "the survey data in our toy example.\n",
    "\n",
    "I'm making sure that questions 1 and 2 have values between 1 and 5 and\n",
    "question 3 matches some regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c547d",
   "metadata": {
    "lines_to_next_cell": 1,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    SurveySchema.validate(data)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e2bca",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "I can then use this schema to both validate the properties of some data at\n",
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1509f6c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sample_data = SurveySchema.example(size=3)\n",
    "display(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d212a41",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "and also sample valid data under the schema's constraints for testing purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac93a79-acfe-475a-9585-a1d379185750",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üìäüìà Define a Specification for Data Types in the Statistical Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3012432e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now the code that you saw in the previous slide is all valid pandera syntax,\n",
    "but actually before diving further into pandera as a specific implementation,\n",
    "I want to define statistical typing more generally, with a\n",
    "few examples to illustrate what I mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fee42a-317a-4780-9071-9d2ba1368e74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> Statistical typing extends primitive data types with additional\n",
    "> semantics about the properties held by a collection of data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d490c",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "I see statistical typing as a type system that extends\n",
    "primitive data types like booleans, strings, and floats with additional semantics\n",
    "about the properties held by a collection of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5845769-8fc7-462d-9369-f24456b5d9bd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Boolean ‚Üí Bernoulli`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d63a7e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So for instance, the boolean data type consists of two possible\n",
    "values: true and false. In statistics speak, we would call this the support of\n",
    "a particular data distribution.\n",
    "\n",
    "Now we can extend booleans to Bernoulli types, and to do that\n",
    "we'd need to supply one more piece of metadata, which is a probability\n",
    "mass function that maps values to probabilities, all of which sum to one.\n",
    "\n",
    "This is sufficient to specify a Bernoulli distribution that we can name, for example\n",
    "a `FairCoin` type, and you can imagine assigning a variable of this type\n",
    "to some data, and then performing statistical operations on it, for example\n",
    "getting the mean or mode of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadae0f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "x1 = True\n",
    "x2 = False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10b72a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "support: Set[bool] = {x1, x2}\n",
    "probability_distribution: Dict[str, float] = {True: 0.5, False, 0.5}\n",
    "FairCoin = Bernoulli(support, probability_distribution)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c1d341",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "data: FairCoin = [1, 0, 0, 1, 1, 0]\n",
    "\n",
    "mean(data)\n",
    "mode(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf8a403-1fd6-4fec-aba9-de2f6116ee95",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Enum ‚Üí Categorical`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d48208",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can generalize booleans to enumerations, which gives us a way of expressing\n",
    "a type with a finite set of values, for example we can define a set of animals\n",
    "consisting of cats, dogs, and cows.\n",
    "\n",
    "Enums can be extended to Categorical types by providing a\n",
    "probability mass function as you saw in the previous slide, in addition\n",
    "to a flag that indicates whether the values are ordered or not. Here we\n",
    "define a FarmAnimals categorical type with a particular distribution of\n",
    "animals that you might find in a farm.\n",
    "\n",
    "You can imagine doing runtime type checks on data associated with the\n",
    "FarmAnimals type to make sure it follows the specified distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d33e0e-6540-40d0-ba80-b5d5ef436008",
   "metadata": {},
   "source": [
    "```python\n",
    "class Animal(Enum):\n",
    "    CAT = 1\n",
    "    DOG = 2\n",
    "    COW = 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551548a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "FarmAnimals = Categorical(\n",
    "    Animal,\n",
    "    probabilities={\n",
    "        Animal.CAT: 0.01,\n",
    "        Animal.DOG: 0.04,\n",
    "        Animal.COW: 0.95,\n",
    "    },\n",
    "    ordered=False,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e18912",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "data: FarmAnimals = [Animal.CAT] * 50 + [Animal.DOG] * 50\n",
    "\n",
    "check_type(data)  # raise a RuntimeError\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff555708-ca1d-4d8c-953a-fd13036012ee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Float ‚Üí Gaussian`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5f471f",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The last example I wanted to go through is to extend floats into Gaussian\n",
    "types. This is conceptually simple because gaussian distributions only\n",
    "have two parameters, which is the mean and standard deviation of the distribution.\n",
    "Here we've defined a `TreeHeight` type whose mean is 10 and standard deviation\n",
    "is 1.\n",
    "\n",
    "The cool thing about these types is that, just like the property-based\n",
    "testing example that I showed you earlier, I could potentially use them\n",
    "to sample data for the purpose of unit testing. So If I have a function that\n",
    "processes data drawn from the TreeHeight distribution, I should be able to\n",
    "draw samples from this type in my unit tests, pass is to my `process_data`\n",
    "function, and then make assertions about the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a3fd3-a053-4569-8213-58a411497cba",
   "metadata": {},
   "source": [
    "```python\n",
    "TreeHeight = Gaussian(mean=10, standard_deviation=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3fab0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python  \n",
    "def test_process_data():\n",
    "    data: List[float] = sample(TreeHeight)\n",
    "    result = process_data(data)\n",
    "    assert ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb2b30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Have you ever done something like this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a23b6e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now I'd like to make the point that statistical typing isn't really new...\n",
    "when I first thought of the term, I googled around for some time and to my\n",
    "surprise I could only find one or two blog posts that specifically used\n",
    "the term in the same way that I was thinking about it.\n",
    "\n",
    "And to prove this point, I want you to consider the following code snippet,\n",
    "and don't worry too much about what the function actually does, just take\n",
    "a look at the end. If you've ever written assert statements that\n",
    "do runtime validations to check whether the output fulfills certain assumptions\n",
    "like value ranges or other such properties, then congratulations, you've been doing\n",
    "statistical typing all along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23d86d8-0b30-4384-b9a8-108d0673dedd",
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def normalize(x: List[float]):\n",
    "    \"\"\"Mean-center and scale with standard deviation\"\"\"\n",
    "    mean = sum(x) / len(x)\n",
    "    std = math.sqrt(sum((i - mean) ** 2 for i in x) / len(x))\n",
    "    x_norm = [(i - mean) / std for i in x]\n",
    "\n",
    "    # runtime assertions\n",
    "    assert any(i < 0 for i in x_norm)\n",
    "    assert any(i > 0 for i in x_norm)\n",
    "\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45547312-8a57-4a87-adaf-f49a529b48b3",
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### ü§Ø You've Been Doing Statistical Typing All Along"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b37bb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Statistical Type Specification: Types as Schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093169e5",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So to try and codify a few of these ideas, we can think of statistical\n",
    "types as potentially multivariate schemas where for each variable, I\n",
    "can define a few things:\n",
    "\n",
    "- the primitive data type that each element in the distribution belongs to\n",
    "- a set of deterministic properties that the type must adhere to\n",
    "- a set of probabilistic properties, such as the distributions that apply\n",
    "  to the variable along with their sufficient statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9006d6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For each variable in my dataset, define:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270d5f2d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **primitive datatype**: `int`, `float`, `bool`, `str`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efed42c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **deterministic properties**: domain of possible values, e.g. `x >= 0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeade1a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **probabilistic properties**: distributions that apply to the variable and\n",
    "  their sufficient statistics, e.g. `mean` and `standard deviation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2306e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d047a1",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The implications of a fully implemented statistical type system are that:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7744947",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "Some statistical properties can be checked statically, e.g. the mean operation cannot be applied to categorical data\n",
    "```python\n",
    "mean(categorical) ‚ùå\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ea519",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "Other properties can only be checked at runtime, e.g. this sample of data is drawn from a Gaussian\n",
    "```python\n",
    "scipy.stats.normaltest(normalize(raw_data))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d8ed60",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "Schemas can be implemented as generative data contracts that can be used for type checking and sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513c5c0d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üõ† Statistical Typing in Practice with `pandera`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aa4ca3",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To illustrate this last implication, it's time to look at a concrete example\n",
    "using pandera, which I'd say is a rough and incomplete implementation of statistical\n",
    "typing, but many of the ideas are there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37578571-4fae-4b56-90c8-87e572af4f61",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suppose we're building a predictive model of house prices given features about different houses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f9ecd9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "raw_data = \"\"\"\n",
    "square_footage,n_bedrooms,property_type,price\n",
    "750,1,condo,200000\n",
    "900,2,condo,400000\n",
    "1200,2,house,500000\n",
    "1100,3,house,450000\n",
    "1000,2,condo,300000\n",
    "1000,2,townhouse,300000\n",
    "1200,2,townhouse,350000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b276b0",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Suppose we're building a predictive model of house prices given features\n",
    "about different houses. You can see from the raw data that we're working\n",
    "with four variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e6566d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "- `square_footage`: positive integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f31dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `n_bedrooms`: positive integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96142eab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `property type`: categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb121ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- üéØ `price`: positive real number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c27d2c9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b964071d",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "And we can think of our pipeline in two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6146deb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process_data(raw_data):  # step 1: prepare data for model training\n",
    "    ...\n",
    "    \n",
    "def train_model(processed_data): # step 2: fit a model on processed data\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abacb1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Define Schemas with `pandera`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a352e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Next we'll define schemas in pandera, which in practice requires a little bit of\n",
    "data exploration to get a sense of what the data look like.\n",
    "\n",
    "Here you can see we're defining a BaseSchema, which we'll use as the\n",
    "foundational type, and we'll have our raw and processed data inherit from it.\n",
    "\n",
    "From these schema definitions, you can immediately see which variables the\n",
    "raw and processed data have in common, but you can also see what the differences\n",
    "are. Namely, that the raw data has a `property_type` variable containing strings\n",
    "that need to be converted into a set of binary indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287b8e2c",
   "metadata": {
    "lines_to_next_cell": 1,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandera as pa\n",
    "from pandera.typing import Series, DataFrame\n",
    "\n",
    "PROPERTY_TYPES = [\"condo\", \"townhouse\", \"house\"]\n",
    "\n",
    "\n",
    "class BaseSchema(pa.SchemaModel):\n",
    "    square_footage: Series[int] = pa.Field(in_range={\"min_value\": 0, \"max_value\": 3000})\n",
    "    n_bedrooms: Series[int] = pa.Field(in_range={\"min_value\": 0, \"max_value\": 10})\n",
    "    price: Series[int] = pa.Field(in_range={\"min_value\": 0, \"max_value\": 1000000})\n",
    "\n",
    "    class Config:\n",
    "        coerce = True\n",
    "\n",
    "\n",
    "class RawData(BaseSchema):\n",
    "    property_type: Series[str] = pa.Field(isin=PROPERTY_TYPES)\n",
    "\n",
    "\n",
    "class ProcessedData(BaseSchema):\n",
    "    property_type_condo: Series[int] = pa.Field(isin=[0, 1])\n",
    "    property_type_house: Series[int] = pa.Field(isin=[0, 1])    \n",
    "    property_type_townhouse: Series[int] = pa.Field(isin=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a722f7e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pipeline\n",
    "\n",
    "With Type Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d0622b",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can then add type annotations to our `process_data` and `train_model`\n",
    "functions to make sure that the inputs and outputs conform with the schema\n",
    "definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3568be05",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "@pa.check_types\n",
    "def process_data(raw_data: DataFrame[RawData]) -> DataFrame[ProcessedData]:\n",
    "    ...\n",
    "\n",
    "@pa.check_types\n",
    "def train_model(processed_data: DataFrame[ProcessedData]):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a3022",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pipeline\n",
    "\n",
    "With Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e235f2",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can fill in our functions with actual implementations using pandas\n",
    "and sklearn, to process the data and train a model, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4534dcfa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "@pa.check_types\n",
    "def process_data(raw_data: DataFrame[RawData]) -> DataFrame[ProcessedData]:\n",
    "    return pd.get_dummies(\n",
    "        raw_data.astype({\"property_type\": pd.CategoricalDtype(PROPERTY_TYPES)})\n",
    "    )\n",
    "\n",
    "\n",
    "@pa.check_types\n",
    "def train_model(processed_data: DataFrame[ProcessedData]) -> BaseEstimator:\n",
    "    return LinearRegression().fit(\n",
    "        X=processed_data.drop(\"price\", axis=1),\n",
    "        y=processed_data[\"price\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e7888",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Running the Pipeline\n",
    "\n",
    "Validate the statistical type of raw and processed data every time we\n",
    "run our pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343de557",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The cool thing about this is that our processing and training functions now\n",
    "inherently validate our raw and processed data every time we run our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57008926",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ model training successful!\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "\n",
    "def run_pipeline(raw_data):\n",
    "    processed_data = process_data(raw_data)\n",
    "    estimator = train_model(processed_data)\n",
    "    # evaluate model, save artifacts, etc...\n",
    "    print(\"‚úÖ model training successful!\")\n",
    "\n",
    "\n",
    "run_pipeline(pd.read_csv(StringIO(raw_data.strip())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216c00e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fail Early and with Useful Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3794fe6",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "And, if we happen to ingest invalid data, the pipeline fails early and we're\n",
    "provided useful information about what exactly went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f53131c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in check_types decorator of function 'process_data': <Schema Column(name=property_type, type=<class 'str'>)> failed element-wise validator 0:\n",
      "<Check isin: isin({'house', 'condo', 'townhouse'})>\n",
      "failure cases:\n",
      "   index failure_case\n",
      "0      0      unknown\n"
     ]
    }
   ],
   "source": [
    "invalid_data = \"\"\"\n",
    "square_footage,n_bedrooms,property_type,price\n",
    "750,1,unknown,200000\n",
    "900,2,condo,400000\n",
    "1200,2,house,500000\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    run_pipeline(pd.read_csv(StringIO(invalid_data.strip())))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e49c7aa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Schemas as Generative Contracts\n",
    "\n",
    "Define property-based unit tests with `hypothesis`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb5e0b1",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To circle back to property-based testing, pandera exposes a `strategy`\n",
    "method that compiles the schema metadata into a hypothesis strategy that\n",
    "you can use in your unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd75f27",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from hypothesis import given\n",
    "\n",
    "\n",
    "@given(RawData.strategy(size=3))\n",
    "def test_process_data(raw_data):\n",
    "    process_data(raw_data)\n",
    "    \n",
    "@given(ProcessedData.strategy(size=3))\n",
    "def test_train_model(processed_data):\n",
    "    estimator = train_model(processed_data)\n",
    "    predictions = estimator.predict(processed_data.drop(\"price\", axis=1))\n",
    "    assert len(predictions) == processed_data.shape[0]\n",
    "\n",
    "def run_test_suite():\n",
    "    test_process_data()\n",
    "    test_train_model()\n",
    "    print(\"‚úÖ tests successful!\")    \n",
    "    \n",
    "run_test_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36374de",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Catch Errors in Data Processing Code\n",
    "\n",
    "Define property-based unit tests with `hypothesis`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451dda32",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This becomes useful because in the case that we've implemented something\n",
    "wrong, we'll also get a useful error message. Here pandera is complaining\n",
    "that the output of `process_data` doesn't contain the variable\n",
    "`property_type_condo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "857b8b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falsifying example: test_process_data(\n",
      "    raw_data=   square_footage  n_bedrooms  price property_type\n",
      "    0               0           0      0         condo\n",
      "    1               0           0      0         condo\n",
      "    2               0           0      0         condo,\n",
      ")\n",
      "error in check_types decorator of function 'process_data': column 'property_type_condo' not in dataframe\n",
      "   square_footage  n_bedrooms  price property_type\n",
      "0               0           0      0         condo\n",
      "1               0           0      0         condo\n",
      "2               0           0      0         condo\n"
     ]
    }
   ],
   "source": [
    "@pa.check_types\n",
    "def process_data(raw_data: DataFrame[RawData]) -> DataFrame[ProcessedData]:\n",
    "    return raw_data\n",
    "\n",
    "try:\n",
    "    run_test_suite()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6613f8e3-5348-4c9b-8899-d9c16d898512",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bootstrapping a Schema from Sample Data\n",
    "\n",
    "For some datasets, it might make sense to infer a schema from a sample of\n",
    "data and go from there:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d647fc",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Finally, you can even bootstrap a schema from a sample of data because it\n",
    "can be tedious to write a schema from scratch. All you have to do is\n",
    "call the `infer_schema` function, which you can then write out in yaml format\n",
    "or as a python script to further edit and refine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d324f7a-e837-4cc7-b406-d5abe2eb0e36",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   square_footage  n_bedrooms property_type   price\n",
      "0             750           1         condo  200000\n",
      "1             900           2         condo  400000\n",
      "2            1200           2         house  500000\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv(StringIO(raw_data.strip()))\n",
    "display(raw_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01cb8dbb",
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Schema DataFrameSchema(\n",
      "    columns={\n",
      "        'square_footage': <Schema Column(name=square_footage, type=int64)>\n",
      "        'n_bedrooms': <Schema Column(name=n_bedrooms, type=int64)>\n",
      "        'property_type': <Schema Column(name=property_type, type=str)>\n",
      "        'price': <Schema Column(name=price, type=int64)>\n",
      "    },\n",
      "    checks=[],\n",
      "    coerce=True,\n",
      "    pandas_dtype=None,\n",
      "    index=<Schema Index(name=None, type=int64)>,\n",
      "    strict=False\n",
      "    name=None,\n",
      "    ordered=False\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "schema = pa.infer_schema(raw_df)\n",
    "schema.to_yaml()\n",
    "schema.to_script()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82acfd52-708a-4159-916e-0a6cd270ad56",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ü™õü™ìü™ö Use Cases\n",
    "\n",
    "- CI tests for ETL/model training pipeline\n",
    "- Alerting for dataset shift\n",
    "- Monitoring model quality in production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a0ec63",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To sum up the practical use cases of statistical typing and pandera in\n",
    "particular, you can use it in the context of continuous integration tests\n",
    "for your ETL or modeling pipelines, but you can also use it for alerting\n",
    "when detecting dataset shift, or monitoring the quality of your model's\n",
    "predictions in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210ae03",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üèé Where Can this Idea Go Next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b3a60",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "But to go from practical use cases into theoretical applications, I want\n",
    "to end with a few ideas that might be interesting to consider when thinking\n",
    "about the question of type systems for data science and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98fa09",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Statically analyze code that performs statistical operations\n",
    "```python\n",
    "FarmAnimals = Categorical(\n",
    "    Animal,\n",
    "    probabilities={\n",
    "        Animal.CAT: 0.01,\n",
    "        Animal.DOG: 0.04,\n",
    "        Animal.COW: 0.95,\n",
    "    },\n",
    "    ordered=False,\n",
    ")\n",
    "\n",
    "data: FarmAnimals = [Animal.CAT] * 50 + [Animal.DOG] * 50\n",
    "mean(data)  # ‚ùå cannot apply mean to Categorical\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8afcd51",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The first idea is that it would be really nice to be able to statically\n",
    "analyze code to call out cases where statistical operations don't make sense\n",
    "given some type.\n",
    "\n",
    "So returning to the FarmAnimal example for earlier, this would mean that\n",
    "even before running code, we could tell that computing the mean of a categorical\n",
    "distribution doesn't make sense and our type linter should be able to tell us that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f857d77d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Infer model architecture space based on function signatures\n",
    "```python\n",
    "def model(input_data: Gaussian) -> Bernoulli:\n",
    "    ...\n",
    "\n",
    "type(model)\n",
    "# [LogisticRegression, RandomForestClassifier, ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb79b2a",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The second idea is that it would be possible to infer the model architecture\n",
    "space based on function signatures with statistical types. So in theory\n",
    "if I have a function that takes a Gaussian distribution as input and outputs\n",
    "a Bernoulli distribution, we should be able to infer the space of valid model\n",
    "architectures that could approximate this function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16176284",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Infer Statistical Types from Data\n",
    "\n",
    "Model-based statistical types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5c86c",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "And finally, maybe the whackiest idea is to infer statistical types from\n",
    "data. It's not always the case that my data can be neatly characterized\n",
    "by the theoretical statistical distributions we know about today. For example,\n",
    "image data or natural language data might be drawn from a very complex\n",
    "manifold that would be impossible to write down manually.\n",
    "\n",
    "In this case we'd want a schema inference routine that can be arbitrarily\n",
    "complex, to describe statistical types that can also be arbitrarily complex,\n",
    "using data that can be encoded as a statistical model, where the model\n",
    "artifacts can lend themselves as components in a schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b0406",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- schema inference can be arbitrarily complex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37361d22",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- statistical types can also be arbitrarily complex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee523b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- data can be encoded as statistical models, and those model artifacts can be\n",
    "  used as components in a schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73b3fb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GAN Schema\n",
    "\n",
    "In theory, a generative adversarial network can be used as a schema to validate\n",
    "real-world data and generate synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39047cfe",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To illustrate this final point, let's consider generative adversarial\n",
    "networks. In theory, a GAN can be used as a schema to validate real-world\n",
    "data but also generate synthetic data. During training you draw real samples\n",
    "from the real world and fake data from a generator whose objective is to fool the\n",
    "discriminator into thinking that the its synthetic data is real.\n",
    "Conversely, the discriminator's objective is to accurately tell when a data point\n",
    "is real or fake."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b59cdb3",
   "metadata": {},
   "source": [
    "<div class=\"mermaid\">\n",
    "graph TB\n",
    "  subgraph GAN Architecture\n",
    "  G[generator]\n",
    "  D[discriminator]\n",
    "  end\n",
    "  W[real world] --real data--> D\n",
    "  G --synthetic data--> D\n",
    "  D --> P[real/fake]\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820ef42",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GAN Schema\n",
    "\n",
    "The discriminator, which is typically discarded after training, can validate\n",
    "real or upstream synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f68c39",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Typically, after training a GAN people only care about the generator and discard\n",
    "the discriminator. However, in our case we can actually use the discriminator\n",
    "to validate data by telling us whether a particular data point is real or\n",
    "fake. We can also use the generator for its primary purpose of synthesizing\n",
    "data for testing our model training functions."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fe6d6a4",
   "metadata": {},
   "source": [
    "<div class=\"mermaid\">\n",
    "graph LR\n",
    "  subgraph GAN Schema\n",
    "  G[generator]\n",
    "  D[discriminator]\n",
    "  end\n",
    "  P[data processor] --real/synthetic data--> D\n",
    "  G --synthetic data--> M[model trainer]\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385b568",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation and Data Synthesis for Complex Statistical Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a98269",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In effect, this would imply that we can implement validation and data\n",
    "synthesis modules for complex statistical types, for example, an image\n",
    "dataset with a particular set of categories describing those images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e4bae94",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image1.jpeg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image2.jpeg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image3.jpeg</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image4.jpeg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        images  class\n",
       "0  image1.jpeg    cat\n",
       "1  image2.jpeg    dog\n",
       "2  image3.jpeg    cow\n",
       "3  image4.jpeg  horse"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame({\n",
    "    \"category\": [\"cat\", \"dog\", \"cow\", \"horse\", \"...\"],\n",
    "    \"images\": [\"image1.jpeg\", \"image2.jpeg\", \"image3.jpeg\", \"image4.jpeg\", \"...\"],\n",
    "})\n",
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8239a91",
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "class ImageSchema(pa.SchemaModel):\n",
    "    category: Series[str] = pa.Field(isin=[\"cat\", \"dog\", \"cow\", \"horse\", \"...\"])\n",
    "    images: Series[Image] = pa.Field(drawn_from=GenerativeAdversarialNetwork(\"weights.pt\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e57196",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In theory, it would be possible to define a schema like this, where we have\n",
    "an Image type that points to a jpeg file. At validation time, that file is\n",
    "read into memory and passed into a GAN to verify that the image is drawn from\n",
    "a similar distribution as what we saw during training time. This might be\n",
    "useful in production to at least warn us when an image is out of distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca9f710",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Takeaway\n",
    "\n",
    "Statistical typing extends primitive data types into the statistical domain,\n",
    "opening up a bunch of testing capabilities that make statistical code\n",
    "more robust and easier to reason about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc8381",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So I'm hoping that in this last section I've given you some food for thought,\n",
    "and really the main takeaway I want to leave you with is that statistical\n",
    "typing extends primitive data types by enforcing a set of deterministic and\n",
    "probabilistic properties about a collection of data points.\n",
    "\n",
    "This opens up a bunch of testing capabilities that make the code that we write as\n",
    "data scientists and ML practitioners more robust and easier to reason about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a67b73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thanks!\n",
    "\n",
    "<i class=\"fa fa-envelope\" aria-hidden=\"true\"></i> niels.bantilan@gmail.com\n",
    "<br>\n",
    "<i class=\"fa fa-twitter\" aria-hidden=\"true\"></i> [@cosmicbboy](https://twitter.com/cosmicBboy)\n",
    "<br>\n",
    "<i class=\"fa fa-github\" aria-hidden=\"true\"></i> [cosmicBboy](https://github.com/cosmicBboy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b6baa",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "And with that I'd like to thank you for your time and attention.\n",
    "\n",
    "Please feel free to reach out to me via email or on twitter or github\n",
    "\n",
    "I hope you got something out of this talk, and I hope you enjoy the rest of the conference!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "pandera-presentations",
   "language": "python",
   "name": "pandera-presentations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
